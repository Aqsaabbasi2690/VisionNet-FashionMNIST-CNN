Image Classification using Upgraded Convolutional Neural Network (CNN)
# Project Overview

This project implements an Upgraded Convolutional Neural Network (CNN) for image classification.
The model is designed to improve performance over a basic CNN by incorporating:

Batch Normalization

Dropout Regularization

Data Augmentation

Improved Architecture Depth

Adam Optimizer

Early Stopping

The goal is to achieve better generalization and higher validation accuracy while preventing overfitting.

Model Architecture

The CNN consists of:

Multiple Conv2D layers

BatchNormalization after convolution

MaxPooling layers

Dropout layers

Fully Connected Dense layers

Softmax output layer

Architecture Flow:

Input Image
â†’ Conv2D + ReLU
â†’ BatchNorm
â†’ MaxPooling
â†’ Dropout
â†’ Conv2D + ReLU
â†’ BatchNorm
â†’ MaxPooling
â†’ Dropout
â†’ Flatten
â†’ Dense
â†’ Dropout
â†’ Output Layer (Softmax)

ğŸ“‚ Project Structure

VisionNet-FashionMNIST-CNN

â”œâ”€â”€ fashion_cnn.ipynb

â”œâ”€â”€ best_fashion_cnn.keras

â”œâ”€â”€ fashion_classifier_production.keras

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ README.md


ğŸ“Š Dataset

Images are organized in class-wise folders.

Supports multi-class classification.

Data augmentation is applied during training to improve robustness.

Example structure:

dataset/
   â”œâ”€â”€ class_1/
   â”œâ”€â”€ class_2/
   â”œâ”€â”€ class_3/

âš™ï¸ Installation

Clone the repository:

git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name


Install dependencies:

pip install -r requirements.txt


Model will:

Train on training data

Validate on validation data

Save the best model

ğŸ“ˆ Results

Improved validation accuracy compared to basic CNN

Reduced overfitting using Dropout

Stable training using Batch Normalization

Example:

Training Accuracy: 94%
Validation Accuracy: 91%

ğŸ› ï¸ Technologies Used

Python

TensorFlow / Keras

NumPy

Matplotlib

ğŸ” Key Improvements Over Basic CNN
| Feature             | Basic CNN | Upgraded CNN |
| ------------------- | --------- | ------------ |
| Batch Normalization | âŒ         | âœ…            |
| Dropout             | âŒ         | âœ…            |
| Data Augmentation   | âŒ         | âœ…            |
| Regularization      | Limited   | Improved     |
| Overfitting Control | Weak      | Strong       |

ğŸ¯ Future Improvements

Transfer Learning (MobileNet / EfficientNet)

Hyperparameter Tuning

Model Deployment (Streamlit / Flask)

Confusion Matrix & Classification Report

ğŸ‘©â€ğŸ’» Author

Aqsa Abbasi

â­ If You Like This Project

Give this repository a â­ and connect with me on LinkedIn!
